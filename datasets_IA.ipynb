{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "66dcc566",
      "metadata": {},
      "source": [
        "# Downlaod datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "18699706",
      "metadata": {
        "id": "18699706"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import shutil\n",
        "import numpy as np\n",
        "import glob\n",
        "from numpy.linalg import norm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "1526b743",
      "metadata": {
        "id": "1526b743"
      },
      "outputs": [],
      "source": [
        "dataset_dir_face = \"./gerador-mensagens/database_face\"\n",
        "extract_path_face = f\"{dataset_dir_face}/images\"\n",
        "zip_path_face = f\"{dataset_dir_face}/facial-emotion-expressions.zip\"\n",
        "path_train_path_face = f'{dataset_dir_face}/images/train'\n",
        "path_validation_path_face = f'{dataset_dir_face}/images/validation'\n",
        "dataset_dir_futebol = \"./gerador-mensagens/database_futebol\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "d9cb9344",
      "metadata": {
        "id": "d9cb9344"
      },
      "outputs": [],
      "source": [
        "os.makedirs(dataset_dir_face, exist_ok=True)\n",
        "\n",
        "if not os.path.exists(zip_path_face):\n",
        "    !curl -L -o {zip_path_face} https://www.kaggle.com/api/v1/datasets/download/samaneheslamifar/facial-emotion-expressions\n",
        "\n",
        "if not os.path.exists(extract_path_face):\n",
        "    zipfile.ZipFile(zip_path_face, 'r').extractall(dataset_dir_face)\n",
        "\n",
        "classes = os.listdir(path_train_path_face)\n",
        "for folder in classes:\n",
        "    if folder not in [\"happy\", \"sad\"]:\n",
        "        shutil.rmtree(os.path.join(path_train_path_face, folder))\n",
        "        shutil.rmtree(os.path.join(path_validation_path_face, folder))\n",
        "    else:\n",
        "        train_files = glob.glob(os.path.join(path_train_path_face, folder, '*'))\n",
        "        validation_files = glob.glob(os.path.join(path_validation_path_face, folder, '*'))\n",
        "        \n",
        "        for i, file_path in enumerate(validation_files):\n",
        "            new_file_path = os.path.join(path_validation_path_face, folder, f\"{folder}_{i+1}.jpg\")\n",
        "            os.rename(file_path, new_file_path)\n",
        "            \n",
        "        for i, file_path in enumerate(train_files):\n",
        "            new_file_path = os.path.join(path_train_path_face, folder, f\"{folder}_{i+1}.jpg\")\n",
        "            os.rename(file_path, new_file_path)\n",
        "\n",
        "if os.path.exists(f\"{extract_path_face}/images\"):\n",
        "    shutil.rmtree(f\"{extract_path_face}/images\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "8c5b3ef8",
      "metadata": {},
      "outputs": [],
      "source": [
        "if not os.path.exists(f\"{dataset_dir_futebol}/futebol_logos.zip\"):\n",
        "    os.makedirs(dataset_dir_futebol, exist_ok=True)\n",
        "    !curl -L -o {dataset_dir_futebol}/futebol_logos.zip https://github.com/luukhopman/football-logos/archive/refs/heads/master.zip\n",
        "\n",
        "if not os.path.exists(f\"{dataset_dir_futebol}/database_futebol\"):\n",
        "    zipfile.ZipFile(f\"{dataset_dir_futebol}/futebol_logos.zip\", 'r').extractall(dataset_dir_futebol)\n",
        "    os.rename(f\"{dataset_dir_futebol}/football-logos-master\", f\"{dataset_dir_futebol}/database_futebol\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49c4b44a",
      "metadata": {},
      "source": [
        "# Criação dos modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9f98952c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1b6ebe30",
      "metadata": {},
      "outputs": [],
      "source": [
        "database_train = image_dataset_from_directory(\n",
        "    path_train_path_face,\n",
        "    image_size=(48, 48),\n",
        "    batch_size=32,\n",
        "    label_mode=\"categorical\",\n",
        "    color_mode=\"grayscale\",\n",
        "    seed=123,\n",
        "    shuffle=True\n",
        ").map(lambda x, y: (x / 255.0, y))\n",
        "\n",
        "database_validation = image_dataset_from_directory(\n",
        "    path_validation_path_face,\n",
        "    image_size=(48, 48),\n",
        "    batch_size=32,\n",
        "    label_mode=\"categorical\",\n",
        "    color_mode=\"grayscale\",\n",
        "    seed=123,\n",
        "    shuffle=True\n",
        ").map(lambda x, y: (x / 255.0, y))\n",
        "\n",
        "model = models.Sequential([\n",
        "    layers.InputLayer(input_shape=(48, 48, 1)),\n",
        "    layers.Conv2D(32, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Conv2D(128, (3, 3), activation='relu'),\n",
        "    layers.MaxPooling2D((2, 2)),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128, activation='relu'),\n",
        "    layers.Dense(2, activation='softmax')\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(database_train, validation_data=database_validation, epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "05121dc2",
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('./consumidor-sentimento/model.h5',  include_optimizer=False) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "04ae6264",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "13/13 [==============================] - 5s 321ms/step\n",
            "Embeddings shape: (398, 1280)\n",
            "Labels shape: (398,)\n"
          ]
        }
      ],
      "source": [
        "base_model = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
        "base_model.trainable = False\n",
        "embedding_model = Model(inputs=base_model.input,outputs=tf.keras.layers.GlobalAveragePooling2D()(base_model.output))\n",
        "\n",
        "path_futebol_logos = glob.glob(f\"{dataset_dir_futebol}/database_futebol/logos/*/*.png\")\n",
        "\n",
        "imgs = []\n",
        "labels = []\n",
        "\n",
        "for img_path in path_futebol_logos:\n",
        "    img = image.load_img(img_path, target_size=(224, 224))\n",
        "    img_array = image.img_to_array(img)\n",
        "    imgs.append(img_array)\n",
        "    label = os.path.basename(img_path).split('.')[:-1]\n",
        "    label = '.'.join(label)\n",
        "    labels.append(label)\n",
        "\n",
        "\n",
        "imgs = np.array(imgs)\n",
        "imgs = preprocess_input(imgs)\n",
        "embeddings = embedding_model.predict(imgs, batch_size=32, verbose=1)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print(\"Embeddings shape:\", embeddings.shape)\n",
        "print(\"Labels shape:\", labels.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e31cde71",
      "metadata": {},
      "outputs": [],
      "source": [
        "np.savetxt(\"consumidor-times/futebol_embeddings.txt\", embeddings, delimiter=' ', fmt='%.6f', encoding=\"utf-8\")\n",
        "with open(\"consumidor-times/futebol_labels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
        "    for label in labels:\n",
        "        f.write(label + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "80b97a31",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "def cosine_similarity(a, b):\n",
        "    return np.dot(a, b) / (norm(a) * norm(b))\n",
        "\n",
        "def predict(embedding, embeddings_train, labels_train):\n",
        "    sims = [cosine_similarity(embedding, e) for e in embeddings_train]\n",
        "    return labels_train[np.argmax(sims)]\n",
        "\n",
        "data = np.load(f\"{dataset_dir_futebol}/futebol_embeddings_labels.npz\")\n",
        "embeddings = data['embeddings']\n",
        "labels = data['labels']\n",
        "y_pred = [predict(e, embeddings, labels) for e in embeddings]\n",
        "\n",
        "accuracy = np.mean(np.array(y_pred) == labels)\n",
        "print(f\"Training accuracy: {accuracy * 100:.2f}%\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv (3.10.0)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
